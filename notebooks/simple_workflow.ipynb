{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3bca2e",
   "metadata": {},
   "source": [
    "# Simple LangGraph Workflow\n",
    "This notebook demonstrates how to create a minimal workflow with LangGraph and OpenAI.\n",
    "## Create Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b041a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#add your OPENAI_API_KEY to .env\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5de229",
   "metadata": {},
   "source": [
    "## Test OpenAI Client\n",
    "We send a simple prompt to verify the client is configured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30347053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In a hidden valley, a shy unicorn named Lila discovered a sparkling lake '\n",
      " 'that shimmered under the moonlight. Each night, she would visit the lake and '\n",
      " 'share her dreams with the twinkling stars, who listened and whispered back '\n",
      " 'sweet secrets. One evening, the stars granted Lila a wish, and from that day '\n",
      " 'on, her radiant glow lit up the night, bringing joy to all the creatures in '\n",
      " 'her magical home.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "message = response.output[0].content[0].text\n",
    "pprint(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9c1bd",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "**Objective:** Route a query based on its sentiment to an appropriate response node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab7bdbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_node(state: GraphState) -> GraphState:\n",
    "    query = state[\"query\"]\n",
    "    if any(word in query for word in [\"happy\", \"joy\"]):\n",
    "        classification = \"happy\"\n",
    "    else: \n",
    "        classification = \"angry\"\n",
    "    return {\"classification\": classification}\n",
    "\n",
    "def happy_response_node(state: GraphState) -> GraphState:\n",
    "    return {\"response\": \"Why so happy!\"}\n",
    "\n",
    "def angry_response_node(state: GraphState) -> GraphState:\n",
    "    return {\"response\": \"Why so angry!\"}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c61310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_node(state: GraphState) -> GraphState:\n",
    "    if state[\"classification\"] == \"happy\":\n",
    "        return \"happy_response\"\n",
    "    else:\n",
    "        return \"angry_response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0dd6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "# this contains the information we need to pass between nodes\n",
    "class GraphState(TypedDict):\n",
    "    query: Optional[str] = None # initial \n",
    "    classification: Optional[str] = None # intermediate\n",
    "    response: Optional[str] = None # final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f88f3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f69575b7d50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START,END\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"sentiment_analysis\", sentiment_analysis_node)\n",
    "workflow.add_node(\"happy_response\", happy_response_node)\n",
    "workflow.add_node(\"angry_response\", angry_response_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"sentiment_analysis\")\n",
    "workflow.add_conditional_edges(\"sentiment_analysis\" , decide_node)\n",
    "\n",
    "workflow.add_edge(\"happy_response\",END)\n",
    "workflow.add_edge(\"angry_response\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b756c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a764e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"I'm happy!!\", 'classification': 'happy', 'response': 'Why so happy!'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"query\": \"I'm happy!!\"}\n",
    "result = app.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d33d5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Life is gloomy', 'classification': 'angry', 'response': 'Why so angry!'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"query\": \"Life is gloomy\"}\n",
    "result = app.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63d7a1",
   "metadata": {},
   "source": [
    "## Improve the Workflow\n",
    "Now that we have a working example, let's create a better sentiment analysis step.\n",
    "We'll use gpt-4o-mini to classify the user's sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e4247f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_sentiment_analysis_node(state: GraphState) -> GraphState:\n",
    "    query = state[\"query\"]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Act as a sentiment analyzer and return happy or angry based on the query, don't return anything else\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    classification = response.choices[0].message.content\n",
    "    return {\"classification\": classification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a110e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f6957ac3b90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START,END\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"sentiment_analysis\", gpt_sentiment_analysis_node)\n",
    "workflow.add_node(\"happy_response\", happy_response_node)\n",
    "workflow.add_node(\"angry_response\", angry_response_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"sentiment_analysis\")\n",
    "workflow.add_conditional_edges(\"sentiment_analysis\" , decide_node)\n",
    "\n",
    "workflow.add_edge(\"happy_response\",END)\n",
    "workflow.add_edge(\"angry_response\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba9989a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122247b3",
   "metadata": {},
   "source": [
    "### Run the Improved Workflow\n",
    "The gpt-4o-mini classifier gives us more accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6f7b80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Tommorow is a weekend', 'classification': 'happy', 'response': 'Why so happy!'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"query\": \"Tommorow is a weekend\"}\n",
    "result = app.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d601a66",
   "metadata": {},
   "source": [
    "This concludes the short LangGraph demo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}